{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,RobustScaler\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,classification_report,precision_score,roc_auc_score,matthews_corrcoef,precision_recall_fscore_support,make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    " \n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,RandomForestClassifier,ExtraTreesClassifier,StackingClassifier,VotingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"C:/Users/saich/OneDrive/Desktop/Diabetes_Classification.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=\"Patient number\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'Gender':{\"female\":\"F\",\"male\":\"M\"}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df[\"Gender\"]=le.fit_transform(df[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesterol        50.000\n",
      "Glucose            26.750\n",
      "HDL Chol           21.000\n",
      "Chol/HDL ratio      2.200\n",
      "Age                26.000\n",
      "Gender              1.000\n",
      "Height              6.000\n",
      "Weight             49.750\n",
      "BMI                 8.175\n",
      "Systolic BP        26.000\n",
      "Diastolic BP       15.000\n",
      "waist               8.000\n",
      "hip                 7.000\n",
      "Waist/hip ratio     0.100\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=df[\"Diabetes\"]\n",
    "features=df.drop(columns=\"Diabetes\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No diabetes    277\n",
       "Diabetes        13\n",
       "Name: Diabetes, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTETomek(random_state=42,sampling_strategy=\"minority\") \n",
    "new_features, new_target = sm.fit_resample(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_res=pd.DataFrame(scaler.fit_transform(new_features),columns=list(new_features.columns))\n",
    "y_res=new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes       277\n",
       "No diabetes    277\n",
       "Name: Diabetes, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1,X_test1,Y_train1,Y_test1=train_test_split(X_res,\n",
    "                                               y_res,\n",
    "                                               test_size=0.35,\n",
    "                                               random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to get scores(KFold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_accuracy(model, X, y):\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def evaluate_model_recall_positive(model,X,y):\n",
    "    scoring = {'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") }\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    results =cross_validate(estimator=model,\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    cv=kfold,\n",
    "                                    scoring=scoring)\n",
    "    return results[\"test_recall\"]\n",
    "\n",
    "def evaluate_model_recall_negative(model,X,y):\n",
    "    scoring = {'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") }\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    results =cross_validate(estimator=model,\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    cv=kfold,\n",
    "                                    scoring=scoring)\n",
    "    return results[\"test_recall\"]\n",
    "\n",
    "def evaluate_model_roc_auc(model, X, y):\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='roc_auc', cv=kfold, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "def evaluate_model_matthews_corrcoef(model,X,y):\n",
    "    score=matthews_corrcoef(y,model.predict(X))\n",
    "    return score\n",
    "\n",
    "def evaluate_model_precision(model,X,y):\n",
    "    scoring = {'precision' : make_scorer(recall_score,pos_label=\"Diabetes\") }\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    results =cross_validate(estimator=model,\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    cv=kfold,\n",
    "                                    scoring=scoring)\n",
    "    return results[\"test_precision\"]\n",
    "\n",
    "def evaluate_model_f1score(model,X,y):\n",
    "    scoring = {'f1' : make_scorer(recall_score,pos_label=\"Diabetes\") }\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    results =cross_validate(estimator=model,\n",
    "                                    X=X,\n",
    "                                    y=y,\n",
    "                                    cv=kfold,\n",
    "                                    scoring=scoring)\n",
    "    return results[\"test_f1\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=11.288378916846883, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR=LogisticRegression(C=11.288378916846883,penalty=\"l2\",solver= 'liblinear',random_state=42)\n",
    "\n",
    "LR.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.87      0.80      0.83        96\n",
      " No diabetes       0.82      0.88      0.85        98\n",
      "\n",
      "    accuracy                           0.84       194\n",
      "   macro avg       0.84      0.84      0.84       194\n",
      "weighted avg       0.84      0.84      0.84       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,LR.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "scoring = {'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for recall\n",
    "results1 =cross_validate(estimator=LR,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring=scoring)\n",
    "# for accuracy\n",
    "accuracy1 = model_selection.cross_val_score(LR, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8166666666666668\n",
      "recall score is : 0.8533626873642353\n",
      "roc-auc score is 0.9041860916860915\n",
      "score time is : 0.0036882638931274416\n",
      "fit time is : 0.013091850280761718\n",
      "recall score for No diabetes is : 0.7906561881045324\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy1))\n",
    "print(\"recall score is :\",np.mean(results1[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(LR, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results1[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results1[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=LR,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # param_grid = [\n",
    "# # # #     {\n",
    "# # # #      'penalty' : ['l1', 'l2'],\n",
    "# # # #     'C' : np.logspace(-4, 4, 20),\n",
    "# # # #     'solver' : ['liblinear']}\n",
    "# # # # ]\n",
    "\n",
    "# # # param_grid = [\n",
    "# # #     {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "# # # ]\n",
    "\n",
    "# param_grid = dict(n_neighbors=list(range(10, 31)))\n",
    "# param_grid = dict(n_estimators=[i for i in [10,20,30,40,50,60,70,80,90,100]])\n",
    "# grid=GridSearchCV(etc,param_grid,cv=10,n_jobs=-1)\n",
    "    \n",
    "# # grid = RandomizedSearchCV(knn, param_distributions = param_grid, cv = 10,n_jobs=-1)\n",
    "# grid=GridSearchCV(knn,param_grid,cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decsison Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1=DecisionTreeClassifier(criterion=\"entropy\",max_depth=6,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=42)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.92      0.96      0.94        96\n",
      " No diabetes       0.96      0.92      0.94        98\n",
      "\n",
      "    accuracy                           0.94       194\n",
      "   macro avg       0.94      0.94      0.94       194\n",
      "weighted avg       0.94      0.94      0.94       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,classifier1.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 =cross_validate(estimator=classifier1,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") })\n",
    "\n",
    "accuracy2 = model_selection.cross_val_score(classifier1, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9222222222222223\n",
      "recall score is : 0.8533626873642353\n",
      "roc-auc score is 0.906456154956155\n",
      "score time is : 0.0036882638931274416\n",
      "fit time is : 0.013091850280761718\n",
      "recall score for No diabetes is : 0.8764231601731602\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy2))\n",
    "print(\"recall score is :\",np.mean(results1[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(classifier1, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results1[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results1[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=classifier1,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=model_selection.KFold(n_splits=10),\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=11)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "knn= KNeighborsClassifier(n_neighbors=11,n_jobs=-1)  \n",
    "knn.fit(X_train1, Y_train1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.81      1.00      0.89        96\n",
      " No diabetes       1.00      0.77      0.87        98\n",
      "\n",
      "    accuracy                           0.88       194\n",
      "   macro avg       0.90      0.88      0.88       194\n",
      "weighted avg       0.90      0.88      0.88       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,knn.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 =cross_validate(estimator=knn,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") })\n",
    "\n",
    "accuracy3 = model_selection.cross_val_score(knn, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8638888888888889\n",
      "recall score for Diabetes is : 1.0\n",
      "roc-auc score is 0.9344652014652015\n",
      "score time is : 0.06756148338317872\n",
      "fit time is : 0.005186271667480469\n",
      "recall score for No diabetes is : 0.7307304386285407\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy3))\n",
    "print(\"recall score for Diabetes is :\",np.mean(results3[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(knn, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results3[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results3[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=knn,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.87      0.82      0.84        96\n",
      " No diabetes       0.83      0.88      0.86        98\n",
      "\n",
      "    accuracy                           0.85       194\n",
      "   macro avg       0.85      0.85      0.85       194\n",
      "weighted avg       0.85      0.85      0.85       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,nb.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 =cross_validate(estimator=nb,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") })\n",
    "\n",
    "accuracy4 = model_selection.cross_val_score(nb, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8416666666666668\n",
      "recall score is : 0.8470257889685137\n",
      "roc-auc score is 0.9185032745032744\n",
      "score time is : 0.0020639181137084963\n",
      "fit time is : 0.06796011924743653\n",
      "recall score for No diabetes is : 0.8493380230880231\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy4))\n",
    "print(\"recall score is :\",np.mean(results4[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(nb, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results4[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results4[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=nb,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=model_selection.KFold(n_splits=10),\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf',probability=True)\n",
    "svm.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.92      1.00      0.96        96\n",
      " No diabetes       1.00      0.92      0.96        98\n",
      "\n",
      "    accuracy                           0.96       194\n",
      "   macro avg       0.96      0.96      0.96       194\n",
      "weighted avg       0.96      0.96      0.96       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,svm.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 =cross_validate(estimator=svm,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") })\n",
    "\n",
    "accuracy5 = model_selection.cross_val_score(svm, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9666666666666666\n",
      "recall score is : 0.9941176470588236\n",
      "roc-auc score is 0.9764568764568764\n",
      "score time is : 0.004008698463439942\n",
      "fit time is : 0.09463281631469726\n",
      "recall score for No diabetes is : 0.9385977651930337\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy5))\n",
    "print(\"recall score is :\",np.mean(results5[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(svm, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results5[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results5[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=svm,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.98      1.00      0.99        96\n",
      " No diabetes       1.00      0.98      0.99        98\n",
      "\n",
      "    accuracy                           0.99       194\n",
      "   macro avg       0.99      0.99      0.99       194\n",
      "weighted avg       0.99      0.99      0.99       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,rf.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 =cross_validate(estimator=rf,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"Diabetes\") })\n",
    "\n",
    "accuracy6 = model_selection.cross_val_score(rf, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9805555555555555\n",
      "recall score is : 1.0\n",
      "roc-auc score is 0.9942252192252192\n",
      "score time is : 0.022417140007019044\n",
      "fit time is : 0.332279896736145\n",
      "recall score for No diabetes is : 0.9710227272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy6))\n",
    "print(\"recall score is :\",np.mean(results6[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(rf, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"score time is :\",np.mean(results6[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results6[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=rf,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=model_selection.KFold(n_splits=10),\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     max_depth=6,\n",
       "                                                     random_state=42)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(n_jobs=-1, n_neighbors=11)),\n",
       "                             ('svm', SVC(probability=True)),\n",
       "                             ('LR',\n",
       "                              LogisticRegression(C=11.288378916846883,\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1= VotingClassifier(estimators=[ ('dt', classifier1),('knn',knn),('svm',svm),('LR',LR)], voting='soft')\n",
    "model1.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.93      1.00      0.96        96\n",
      " No diabetes       1.00      0.93      0.96        98\n",
      "\n",
      "    accuracy                           0.96       194\n",
      "   macro avg       0.97      0.96      0.96       194\n",
      "weighted avg       0.97      0.96      0.96       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,model1.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =cross_validate(estimator=model1,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring=scoring)\n",
    "accuracy = model_selection.cross_val_score(LR, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8166666666666668\n",
      "recall score is : 0.9949999999999999\n",
      "score time is : 0.04014756679534912\n",
      "fit time is : 0.03747372627258301\n",
      "recall score for No diabetes is : 0.9112737486298867\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",np.mean(accuracy))\n",
    "print(\"recall score is :\",np.mean(results[\"test_recall\"]))\n",
    "print(\"score time is :\",np.mean(results[\"score_time\"]))\n",
    "print(\"fit time is :\",np.mean(results[\"fit_time\"]))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=model1,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of random forest regression classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(random_state=42),\n",
       "                  n_estimators=15, random_state=8)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logbagClf = BaggingClassifier(rf, n_estimators = 15,random_state=8)\n",
    "logbagClf.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetes       0.96      1.00      0.98        96\n",
      " No diabetes       1.00      0.96      0.98        98\n",
      "\n",
      "    accuracy                           0.98       194\n",
      "   macro avg       0.98      0.98      0.98       194\n",
      "weighted avg       0.98      0.98      0.98       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,logbagClf.predict(X_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.778 \n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f ' % (np.mean(model_selection.cross_val_score(logbagClf, X_train1,Y_train1, scoring='accuracy', cv=cv, n_jobs=-1))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score is : 0.8533626873642353\n",
      "roc-auc score is 0.9882700632700633\n",
      "recall score for No diabetes is : 0.9548147863264299\n"
     ]
    }
   ],
   "source": [
    "print(\"recall score is :\",np.mean(cross_validate(estimator=LR,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring=scoring)[\"test_recall\"]))\n",
    "print(\"roc-auc score is\",np.mean(list(cross_val_score(logbagClf, X_test1, Y_test1, cv=cv, scoring='roc_auc'))))\n",
    "print(\"recall score for No diabetes is :\",np.mean(cross_validate(estimator=logbagClf,\n",
    "                                    X=X_train1,\n",
    "                                    y=Y_train1,\n",
    "                                    cv=cv,\n",
    "                                    scoring={'recall' : make_scorer(recall_score,pos_label=\"No diabetes\") })[\"test_recall\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.9, n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gboost= GradientBoostingClassifier(learning_rate=0.9,random_state=42,n_estimators=250)\n",
    "Gboost.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    n_trees = [10,30, 50, 100,250, 500]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = GradientBoostingClassifier(n_estimators=n)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.860 \n",
      ">30 0.960 \n",
      ">50 0.977 \n",
      ">100 0.977 \n",
      ">250 0.991 \n",
      ">500 0.981 \n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model_recall_positive(model, X_test1,Y_test1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f ' % (name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=750, random_state=42)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adaboost = AdaBoostClassifier(random_state=42,n_estimators=750)\n",
    "Adaboost.fit(X_train1, Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    n_trees = [10,30, 50, 100,250, 500,750,1000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = AdaBoostClassifier(n_estimators=n)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.902 \n",
      ">30 0.933 \n",
      ">50 0.912 \n",
      ">100 0.921 \n",
      ">250 0.958 \n",
      ">500 0.962 \n",
      ">750 0.981 \n",
      ">1000 0.967 \n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model_recall_positive(model, X_test1,Y_test1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f ' % (name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_true,x_true,model):\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(confusion_matrix(y_true, model.predict(x_true)), annot=True)\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['Diabetes', 'No Diabetes']); ax.yaxis.set_ticklabels(['Diabetes', 'No Diabetes']);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=50,random_state=42)\n",
    "etc.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    n_trees = [10,30, 50, 100,250, 500, 1000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = ExtraTreesClassifier(n_estimators=n)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.954 \n",
      ">30 0.963 \n",
      ">50 0.982 \n",
      ">100 0.973 \n",
      ">250 0.963 \n",
      ">500 0.973 \n",
      ">1000 0.973 \n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model_recall_positive(model, X_test1,Y_test1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f ' % (name, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of Adaboost,Gboost,Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Adaboost',\n",
       "                              AdaBoostClassifier(n_estimators=750,\n",
       "                                                 random_state=42)),\n",
       "                             ('Gboost',\n",
       "                              GradientBoostingClassifier(learning_rate=0.9,\n",
       "                                                         n_estimators=250,\n",
       "                                                         random_state=42)),\n",
       "                             ('etc',\n",
       "                              ExtraTreesClassifier(n_estimators=50,\n",
       "                                                   random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=VotingClassifier(estimators=[ ('Adaboost', Adaboost),('Gboost',Gboost),('etc',etc)], voting='soft')\n",
    "model2.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of rf,Gboost,Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              AdaBoostClassifier(n_estimators=750,\n",
       "                                                 random_state=42)),\n",
       "                             ('Gboost',\n",
       "                              RandomForestClassifier(random_state=42)),\n",
       "                             ('etc',\n",
       "                              ExtraTreesClassifier(n_estimators=50,\n",
       "                                                   random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=VotingClassifier(estimators=[ ('rf', Adaboost),('Gboost',rf),('etc',etc)], voting='soft')\n",
    "model3.fit(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.9123684210526315\n",
      "diabetes recall is:  0.959047619047619\n",
      "no diabetes recall is:  0.8638400488400488\n",
      "roc_auc is:  0.906456154956155\n",
      "matthews_corrcoef is:  0.8770736650497879\n",
      "Precision is:  0.959047619047619\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is: \",np.mean(evaluate_model_accuracy(classifier1,X_test1,Y_test1)))\n",
    "print(\"diabetes recall is: \",np.mean(evaluate_model_recall_positive(classifier1,X_test1,Y_test1)))\n",
    "print(\"no diabetes recall is: \",np.mean(evaluate_model_recall_negative(classifier1,X_test1,Y_test1)))\n",
    "print(\"roc_auc is: \",np.mean(evaluate_model_roc_auc(classifier1,X_test1,Y_test1)))\n",
    "print(\"matthews_corrcoef is: \",evaluate_model_matthews_corrcoef(classifier1,X_test1,Y_test1))\n",
    "print(\"Precision is: \",np.mean(evaluate_model_precision(classifier1,X_test1,Y_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# showing Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix(Y_test1,X_test1,etc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df=pd.DataFrame()\n",
    "\n",
    "LR_scores={'accuracy': [0.8505263157894737],\n",
    " 'recall_positive': [0.8851839826839827],\n",
    "\n",
    " 'roc_auc': [0.9041860916860915],\n",
    " 'precision': [0.8851839826839827],\n",
    " \"f1_score\":[0.8851839826839827]}\n",
    "\n",
    "\n",
    "scores_df=pd.DataFrame(LR_scores,index=[\"LR\"])\n",
    "\n",
    "scores_df.loc[\"knn\"] = [np.mean(evaluate_model_accuracy(knn,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(knn,X_test1,Y_test1)),\n",
    "               \n",
    "                       np.mean(evaluate_model_roc_auc(knn,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(knn,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(knn,X_test1,Y_test1))]\n",
    "\n",
    "\n",
    "scores_df.loc[\"classifier1\"] = [np.mean(evaluate_model_accuracy(classifier1,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(classifier1,X_test1,Y_test1)),\n",
    "                 \n",
    "                       np.mean(evaluate_model_roc_auc(classifier1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(classifier1,X_test1,Y_test1)),\n",
    "                               np.mean(evaluate_model_f1score(classifier1,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"svm\"] = [np.mean(evaluate_model_accuracy(svm,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(svm,X_test1,Y_test1)),\n",
    "              \n",
    "                       np.mean(evaluate_model_roc_auc(svm,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(svm,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(svm,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"nb\"] = [np.mean(evaluate_model_accuracy(nb,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(nb,X_test1,Y_test1)),\n",
    "                  \n",
    "                       np.mean(evaluate_model_roc_auc(nb,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(nb,X_test1,Y_test1)),\n",
    "                      np.mean(evaluate_model_f1score(nb,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"rf\"] = [np.mean(evaluate_model_accuracy(rf,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(rf,X_test1,Y_test1)),\n",
    "                \n",
    "                       np.mean(evaluate_model_roc_auc(rf,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(rf,X_test1,Y_test1)),\n",
    "                      np.mean(evaluate_model_f1score(rf,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"Gboost\"] = [np.mean(evaluate_model_accuracy(Gboost,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(Gboost,X_test1,Y_test1)),\n",
    "              \n",
    "                       np.mean(evaluate_model_roc_auc(Gboost,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(Gboost,X_test1,Y_test1)),\n",
    "                          np.mean(evaluate_model_f1score(Gboost,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"Adaboost\"] = [np.mean(evaluate_model_accuracy(Adaboost,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(Adaboost,X_test1,Y_test1)),\n",
    "                  \n",
    "                       np.mean(evaluate_model_roc_auc(Adaboost,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(Adaboost,X_test1,Y_test1)),\n",
    "                            np.mean(evaluate_model_f1score(Adaboost,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"etc\"] = [np.mean(evaluate_model_accuracy(etc,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(etc,X_test1,Y_test1)),\n",
    "                     \n",
    "                       np.mean(evaluate_model_roc_auc(etc,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(etc,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(etc,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"model1\"] = [np.mean(evaluate_model_accuracy(model1,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model1,X_test1,Y_test1)),\n",
    "                     \n",
    "                       np.mean(evaluate_model_roc_auc(model1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model1,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"model2\"] = [np.mean(evaluate_model_accuracy(model2,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model2,X_test1,Y_test1)),\n",
    "                    \n",
    "                       np.mean(evaluate_model_roc_auc(model2,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model2,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model2,X_test1,Y_test1))]\n",
    "\n",
    "scores_df.loc[\"model3\"]=[np.mean(evaluate_model_accuracy(model3,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model3,X_test1,Y_test1)),\n",
    "                    \n",
    "                       np.mean(evaluate_model_roc_auc(model3,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model3,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model3,X_test1,Y_test1))]\n",
    "\n",
    "\n",
    "scores_df.loc[\"LR\"] = [np.mean(evaluate_model_accuracy(LR,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(LR,X_test1,Y_test1)),\n",
    "               \n",
    "                       np.mean(evaluate_model_roc_auc(LR,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(LR,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(LR,X_test1,Y_test1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_scores=pd.DataFrame()\n",
    "\n",
    "LR_scores={'accuracy': [0.8868421052631579],\n",
    " 'recall_positive': [0.9058658008658009],\n",
    "\n",
    " 'roc_auc': [0.9233404928404928],\n",
    " 'precision': [0.9058658008658009],\n",
    " \"f1_score\":[0.9058658008658009]}\n",
    "\n",
    "individual_scores=pd.DataFrame(LR_scores,index=[\"LR\"])\n",
    "\n",
    "individual_scores.loc[\"knn\"] = [np.mean(evaluate_model_accuracy(knn,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(knn,X_test1,Y_test1)),\n",
    "               \n",
    "                       np.mean(evaluate_model_roc_auc(knn,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(knn,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(knn,X_test1,Y_test1))]\n",
    "\n",
    "\n",
    "individual_scores.loc[\"classifier1\"] = [np.mean(evaluate_model_accuracy(classifier1,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(classifier1,X_test1,Y_test1)),\n",
    "                 \n",
    "                       np.mean(evaluate_model_roc_auc(classifier1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(classifier1,X_test1,Y_test1)),\n",
    "                               np.mean(evaluate_model_f1score(classifier1,X_test1,Y_test1))]\n",
    "\n",
    "individual_scores.loc[\"svm\"] = [np.mean(evaluate_model_accuracy(svm,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(svm,X_test1,Y_test1)),\n",
    "              \n",
    "                       np.mean(evaluate_model_roc_auc(svm,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(svm,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(svm,X_test1,Y_test1))]\n",
    "\n",
    "individual_scores.loc[\"nb\"] = [np.mean(evaluate_model_accuracy(nb,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(nb,X_test1,Y_test1)),\n",
    "                  \n",
    "                       np.mean(evaluate_model_roc_auc(nb,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(nb,X_test1,Y_test1)),\n",
    "                      np.mean(evaluate_model_f1score(nb,X_test1,Y_test1))]\n",
    "\n",
    "individual_scores.loc[\"LR\"] = [np.mean(evaluate_model_accuracy(LR,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(LR,X_test1,Y_test1)),\n",
    "               \n",
    "                       np.mean(evaluate_model_roc_auc(LR,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(LR,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(LR,X_test1,Y_test1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom_ensemble_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ensemble_scores=pd.DataFrame()\n",
    "\n",
    "model1_scores={'accuracy': [0.9021052631578949],\n",
    " 'recall_positive': [ 0.9058658008658009],\n",
    "\n",
    " 'roc_auc': [0.9726289266289267],\n",
    " 'precision': [0.9058658008658009],\n",
    " \"f1_score\":[ 0.9058658008658009]}\n",
    "\n",
    "custom_ensemble_scores=pd.DataFrame(model1_scores,index=[\"model1\"])\n",
    "\n",
    "\n",
    "custom_ensemble_scores.loc[\"model2\"] = [np.mean(evaluate_model_accuracy(model2,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model2,X_test1,Y_test1)),\n",
    "                    \n",
    "                       np.mean(evaluate_model_roc_auc(model2,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model2,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model2,X_test1,Y_test1))]\n",
    "\n",
    "custom_ensemble_scores.loc[\"model3\"]=[np.mean(evaluate_model_accuracy(model3,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model3,X_test1,Y_test1)),\n",
    "                    \n",
    "                       np.mean(evaluate_model_roc_auc(model3,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model3,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model3,X_test1,Y_test1))]\n",
    "\n",
    "custom_ensemble_scores.loc[\"model1\"] = [np.mean(evaluate_model_accuracy(model1,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(model1,X_test1,Y_test1)),\n",
    "                    \n",
    "                       np.mean(evaluate_model_roc_auc(model1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(model1,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(model1,X_test1,Y_test1))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble_scores=pd.DataFrame()\n",
    "\n",
    "rf_scores={'accuracy': [0.9689473684210526],\n",
    " 'recall_positive': [0.9517424242424243],\n",
    "\n",
    " 'roc_auc': [0.9931235431235432],\n",
    " 'precision': [0.9608333333333334],\n",
    " \"f1_score\":[0.9608333333333334]}\n",
    "\n",
    "Ensemble_scores=pd.DataFrame(rf_scores,index=[\"rf\"])\n",
    "\n",
    "\n",
    "Ensemble_scores.loc[\"Gboost\"] = [np.mean(evaluate_model_accuracy(Gboost,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(Gboost,X_test1,Y_test1)),\n",
    "              \n",
    "                       np.mean(evaluate_model_roc_auc(Gboost,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(Gboost,X_test1,Y_test1)),\n",
    "                          np.mean(evaluate_model_f1score(Gboost,X_test1,Y_test1))]\n",
    "\n",
    "Ensemble_scores.loc[\"Adaboost\"] = [np.mean(evaluate_model_accuracy(Adaboost,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(Adaboost,X_test1,Y_test1)),\n",
    "                  \n",
    "                       np.mean(evaluate_model_roc_auc(Adaboost,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(Adaboost,X_test1,Y_test1)),\n",
    "                            np.mean(evaluate_model_f1score(Adaboost,X_test1,Y_test1))]\n",
    "\n",
    "Ensemble_scores.loc[\"etc\"] = [np.mean(evaluate_model_accuracy(etc,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(etc,X_test1,Y_test1)),\n",
    "                     \n",
    "                       np.mean(evaluate_model_roc_auc(etc,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(etc,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_f1score(etc,X_test1,Y_test1))]\n",
    "\n",
    "Ensemble_scores.loc[\"rf\"] = [np.mean(evaluate_model_accuracy(rf,X_test1,Y_test1)),\n",
    "                        np.mean(evaluate_model_recall_positive(rf,X_test1,Y_test1)),\n",
    "              \n",
    "                       np.mean(evaluate_model_roc_auc(rf,X_test1,Y_test1)),\n",
    "                       np.mean(evaluate_model_precision(rf,X_test1,Y_test1)),\n",
    "                          np.mean(evaluate_model_f1score(rf,X_test1,Y_test1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall_positive</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.850526</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.904186</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.885184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.946818</td>\n",
       "      <td>0.934465</td>\n",
       "      <td>0.946818</td>\n",
       "      <td>0.946818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classifier1</th>\n",
       "      <td>0.912368</td>\n",
       "      <td>0.959048</td>\n",
       "      <td>0.906456</td>\n",
       "      <td>0.959048</td>\n",
       "      <td>0.959048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.886579</td>\n",
       "      <td>0.891851</td>\n",
       "      <td>0.976457</td>\n",
       "      <td>0.891851</td>\n",
       "      <td>0.891851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.918503</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.828279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  recall_positive   roc_auc  precision  f1_score\n",
       "LR           0.850526         0.885184  0.904186   0.885184  0.885184\n",
       "knn          0.835000         0.946818  0.934465   0.946818  0.946818\n",
       "classifier1  0.912368         0.959048  0.906456   0.959048  0.959048\n",
       "svm          0.886579         0.891851  0.976457   0.891851  0.891851\n",
       "nb           0.849737         0.828279  0.918503   0.828279  0.828279"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall_positive</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.948421</td>\n",
       "      <td>0.959199</td>\n",
       "      <td>0.994225</td>\n",
       "      <td>0.959199</td>\n",
       "      <td>0.959199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gboost</th>\n",
       "      <td>0.953158</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.992477</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaboost</th>\n",
       "      <td>0.943158</td>\n",
       "      <td>0.980909</td>\n",
       "      <td>0.975710</td>\n",
       "      <td>0.980909</td>\n",
       "      <td>0.980909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>0.958947</td>\n",
       "      <td>0.962727</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>0.962727</td>\n",
       "      <td>0.962727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  recall_positive   roc_auc  precision  f1_score\n",
       "rf        0.948421         0.959199  0.994225   0.959199  0.959199\n",
       "Gboost    0.953158         0.990909  0.992477   0.990909  0.990909\n",
       "Adaboost  0.943158         0.980909  0.975710   0.980909  0.980909\n",
       "etc       0.958947         0.962727  0.996970   0.962727  0.962727"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall_positive</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0.907105</td>\n",
       "      <td>0.922532</td>\n",
       "      <td>0.976274</td>\n",
       "      <td>0.930866</td>\n",
       "      <td>0.930866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0.953158</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0.963947</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.996698</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.981818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  recall_positive   roc_auc  precision  f1_score\n",
       "model1  0.907105         0.922532  0.976274   0.930866  0.930866\n",
       "model2  0.953158         0.990909  0.997980   0.990909  0.990909\n",
       "model3  0.963947         0.981818  0.996698   0.981818  0.981818"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_ensemble_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
